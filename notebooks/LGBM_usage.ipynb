{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import Trials\n",
    "\n",
    "from lightgbm import *\n",
    "\n",
    "from shaphypetune import BoostSearch, BoostBoruta, BoostRFE, BoostRFA\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf, y_clf = make_classification(n_samples=8000, n_features=20, n_classes=2, \n",
    "                                   n_informative=4, n_redundant=6, random_state=0)\n",
    "\n",
    "X_clf_train, X_clf_valid, y_clf_train, y_clf_valid = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.3, shuffle=False)\n",
    "\n",
    "X_regr, y_regr = make_classification(n_samples=8000, n_features=20,\n",
    "                                     n_informative=7, random_state=0)\n",
    "\n",
    "X_regr_train, X_regr_valid, y_regr_train, y_regr_valid = train_test_split(\n",
    "    X_regr, y_regr, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.2, 0.1],\n",
    "    'num_leaves': [25, 30, 35],\n",
    "    'max_depth': [10, 12]\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate': stats.uniform(0.09, 0.25),\n",
    "    'num_leaves': stats.randint(20,40),\n",
    "    'max_depth': [10, 12]\n",
    "}\n",
    "\n",
    "param_dist_hyperopt = {\n",
    "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
    "    'max_depth': 15 + hp.randint('num_leaves', 5), \n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}\n",
    "\n",
    "\n",
    "regr_lgbm = LGBMRegressor(n_estimators=150, random_state=0, n_jobs=-1)\n",
    "clf_lgbm = LGBMClassifier(n_estimators=150, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00047 ### eval_score: 0.25942\n",
      "trial: 0002 ### iterations: 00029 ### eval_score: 0.26879\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.25027\n",
      "trial: 0004 ### iterations: 00035 ### eval_score: 0.26033\n",
      "trial: 0005 ### iterations: 00069 ### eval_score: 0.2497\n",
      "trial: 0006 ### iterations: 00044 ### eval_score: 0.25268\n",
      "trial: 0007 ### iterations: 00111 ### eval_score: 0.25511\n",
      "trial: 0008 ### iterations: 00107 ### eval_score: 0.25491\n",
      "trial: 0009 ### iterations: 00093 ### eval_score: 0.24845\n",
      "trial: 0010 ### iterations: 00107 ### eval_score: 0.24726\n",
      "trial: 0011 ### iterations: 00093 ### eval_score: 0.25091\n",
      "trial: 0012 ### iterations: 00082 ### eval_score: 0.25287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostSearch(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "            param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                        'num_leaves': [25, 30, 35]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH ###\n",
    "\n",
    "model = BoostSearch(clf_lgbm, param_grid=param_grid)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=12, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'learning_rate': 0.1, 'num_leaves': 35, 'max_depth': 12},\n",
       " 0.24725564683166487)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.90875, (2400,), (2400, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.predict_proba(X_clf_valid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00019 ### eval_score: 0.05974\n",
      "trial: 0002 ### iterations: 00023 ### eval_score: 0.0625\n",
      "trial: 0003 ### iterations: 00150 ### eval_score: 0.05638\n",
      "trial: 0004 ### iterations: 00032 ### eval_score: 0.05881\n",
      "trial: 0005 ### iterations: 00026 ### eval_score: 0.05976\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.05593\n",
      "trial: 0007 ### iterations: 00023 ### eval_score: 0.06166\n",
      "trial: 0008 ### iterations: 00039 ### eval_score: 0.06223\n",
      "trial: 0009 ### iterations: 00031 ### eval_score: 0.06256\n",
      "trial: 0010 ### iterations: 00054 ### eval_score: 0.06231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostSearch(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "            n_iter=10,\n",
       "            param_grid={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018567F78208>,\n",
       "                        'max_depth': [10, 12],\n",
       "                        'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018566F33248>},\n",
       "            sampling_seed=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH ###\n",
    "\n",
    "model = BoostSearch(\n",
    "    regr_lgbm, param_grid=param_dist,\n",
    "    n_iter=10, sampling_seed=0\n",
    ")\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.1132770716679645, max_depth=12, n_estimators=150,\n",
       "               num_leaves=23, random_state=0),\n",
       " {'learning_rate': 0.1132770716679645, 'num_leaves': 23, 'max_depth': 12},\n",
       " 0.05593005637236878)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7761826315554707, (2400,), (2400, 21))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('boosting_type', 'max_depth', 'learning_rate', 'colsample_bytree')\n",
      "\n",
      "trial: 0001 ### iterations: 00150 ### eval_score: 0.05742\n",
      "trial: 0002 ### iterations: 00119 ### eval_score: 0.05542\n",
      "trial: 0003 ### iterations: 00036 ### eval_score: 0.05962\n",
      "trial: 0004 ### iterations: 00150 ### eval_score: 0.10881\n",
      "trial: 0005 ### iterations: 00150 ### eval_score: 0.16047\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.05253\n",
      "trial: 0007 ### iterations: 00052 ### eval_score: 0.05757\n",
      "trial: 0008 ### iterations: 00150 ### eval_score: 0.05405\n",
      "trial: 0009 ### iterations: 00108 ### eval_score: 0.05791\n",
      "trial: 0010 ### iterations: 00150 ### eval_score: 0.09827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostSearch(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "            n_iter=10,\n",
       "            param_grid={'boosting_type': <hyperopt.pyll.base.Apply object at 0x000001855ED04288>,\n",
       "                        'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x0000018567F7E3C8>,\n",
       "                        'learning_rate': <hyperopt.pyll.base.Apply object at 0x0000018567F78FC8>,\n",
       "                        'max_depth': <hyperopt.pyll.base.Apply object at 0x0000018567F78B08>},\n",
       "            sampling_seed=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH HYPEROPT ###\n",
    "\n",
    "model = BoostSearch(\n",
    "    regr_lgbm, param_grid=param_dist_hyperopt,\n",
    "    n_iter=10, sampling_seed=0\n",
    ")\n",
    "model.fit(\n",
    "    X_regr_train, y_regr_train, trials=Trials(), \n",
    "    eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(colsample_bytree=0.7597292534356749,\n",
       "               learning_rate=0.059836658149176665, max_depth=16,\n",
       "               n_estimators=150, random_state=0),\n",
       " {'boosting_type': 'gbdt',\n",
       "  'colsample_bytree': 0.7597292534356749,\n",
       "  'learning_rate': 0.059836658149176665,\n",
       "  'max_depth': 16},\n",
       " 0.052526187351329794)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7898040197004537, (2400,), (2400, 21))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostBoruta(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "            max_iter=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BORUTA ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, max_iter=200, perc=100)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(n_estimators=150, random_state=0), 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9108333333333334, (2400,), (2400, 9), (2400, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict_proba(X_clf_valid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ELIMINATION (RFE) ###\n",
    "\n",
    "model = BoostRFE(regr_lgbm, min_features_to_select=1, step=1)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(n_estimators=150, random_state=0), 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8171773316485389, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostRFA(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ADDITION (RFA) ###\n",
    "\n",
    "model = BoostRFA(regr_lgbm, min_features_to_select=1, step=1)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(n_estimators=150, random_state=0), 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8171773316485389, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostBoruta(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "            importance_type='shap_importances', max_iter=200,\n",
       "            train_importance=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BORUTA SHAP ###\n",
    "\n",
    "model = BoostBoruta(\n",
    "    clf_lgbm, max_iter=200, perc=100,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(n_estimators=150, random_state=0), 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91125, (2400,), (2400, 11), (2400, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict_proba(X_clf_valid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         importance_type='shap_importances', min_features_to_select=1,\n",
       "         train_importance=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ELIMINATION (RFE) SHAP ###\n",
    "\n",
    "model = BoostRFE(\n",
    "    regr_lgbm, min_features_to_select=1, step=1,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(n_estimators=150, random_state=0), 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8171773316485389, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoostRFA(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         importance_type='shap_importances', min_features_to_select=1,\n",
       "         train_importance=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ADDITION (RFA) SHAP ###\n",
    "\n",
    "model = BoostRFA(\n",
    "    regr_lgbm, min_features_to_select=1, step=1,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(n_estimators=150, random_state=0), 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8171773316485389, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning + Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00066 ### eval_score: 0.23684\n",
      "trial: 0002 ### iterations: 00052 ### eval_score: 0.23871\n",
      "trial: 0003 ### iterations: 00049 ### eval_score: 0.24086\n",
      "trial: 0004 ### iterations: 00048 ### eval_score: 0.2382\n",
      "trial: 0005 ### iterations: 00049 ### eval_score: 0.23586\n",
      "trial: 0006 ### iterations: 00053 ### eval_score: 0.23598\n",
      "trial: 0007 ### iterations: 00126 ### eval_score: 0.23237\n",
      "trial: 0008 ### iterations: 00126 ### eval_score: 0.23805\n",
      "trial: 0009 ### iterations: 00101 ### eval_score: 0.23554\n",
      "trial: 0010 ### iterations: 00100 ### eval_score: 0.23165\n",
      "trial: 0011 ### iterations: 00084 ### eval_score: 0.23291\n",
      "trial: 0012 ### iterations: 00087 ### eval_score: 0.23614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostBoruta(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "            max_iter=200,\n",
       "            param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                        'num_leaves': [25, 30, 35]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH + BORUTA ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, param_grid=param_grid, max_iter=200, perc=100)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=12, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'learning_rate': 0.1, 'num_leaves': 35, 'max_depth': 12},\n",
       " 0.23165415918498178,\n",
       " 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91375, (2400,), (2400, 9), (2400, 2))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict_proba(X_clf_valid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00052 ### eval_score: 0.04664\n",
      "trial: 0002 ### iterations: 00123 ### eval_score: 0.04862\n",
      "trial: 0003 ### iterations: 00150 ### eval_score: 0.04846\n",
      "trial: 0004 ### iterations: 00073 ### eval_score: 0.04777\n",
      "trial: 0005 ### iterations: 00148 ### eval_score: 0.04512\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.04881\n",
      "trial: 0007 ### iterations: 00057 ### eval_score: 0.04667\n",
      "trial: 0008 ### iterations: 00148 ### eval_score: 0.05036\n",
      "trial: 0009 ### iterations: 00080 ### eval_score: 0.04935\n",
      "trial: 0010 ### iterations: 00150 ### eval_score: 0.04769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1, n_iter=10,\n",
       "         param_grid={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018567F78208>,\n",
       "                     'max_depth': [10, 12],\n",
       "                     'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018566F33248>},\n",
       "         sampling_seed=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH + RECURSIVE FEATURE ELIMINATION (RFE) ###\n",
    "\n",
    "model = BoostRFE(\n",
    "    regr_lgbm, param_grid=param_dist, min_features_to_select=1, step=1,\n",
    "    n_iter=10, sampling_seed=0\n",
    ")\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.19192175702007153, max_depth=12, n_estimators=150,\n",
       "               random_state=0),\n",
       " {'learning_rate': 0.19192175702007153, 'num_leaves': 31, 'max_depth': 12},\n",
       " 0.045118545913448174,\n",
       " 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8194474515248205, (2400,), (2400, 8), (2400, 9))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('boosting_type', 'max_depth', 'learning_rate', 'colsample_bytree')\n",
      "\n",
      "trial: 0001 ### iterations: 00150 ### eval_score: 0.05458\n",
      "trial: 0002 ### iterations: 00148 ### eval_score: 0.0459\n",
      "trial: 0003 ### iterations: 00111 ### eval_score: 0.04903\n",
      "trial: 0004 ### iterations: 00150 ### eval_score: 0.10326\n",
      "trial: 0005 ### iterations: 00150 ### eval_score: 0.15731\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.05281\n",
      "trial: 0007 ### iterations: 00071 ### eval_score: 0.0542\n",
      "trial: 0008 ### iterations: 00150 ### eval_score: 0.05331\n",
      "trial: 0009 ### iterations: 00150 ### eval_score: 0.05053\n",
      "trial: 0010 ### iterations: 00150 ### eval_score: 0.09654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFA(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1, n_iter=10,\n",
       "         param_grid={'boosting_type': <hyperopt.pyll.base.Apply object at 0x000001855ED04288>,\n",
       "                     'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x0000018567F7E3C8>,\n",
       "                     'learning_rate': <hyperopt.pyll.base.Apply object at 0x0000018567F78FC8>,\n",
       "                     'max_depth': <hyperopt.pyll.base.Apply object at 0x0000018567F78B08>},\n",
       "         sampling_seed=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH HYPEROPT + RECURSIVE FEATURE ADDITION (RFA) ###\n",
    "\n",
    "model = BoostRFA(\n",
    "    regr_lgbm, param_grid=param_dist_hyperopt, min_features_to_select=1, step=1,\n",
    "    n_iter=10, sampling_seed=0\n",
    ")\n",
    "model.fit(\n",
    "    X_regr_train, y_regr_train, trials=Trials(), \n",
    "    eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(colsample_bytree=0.8515260655364685,\n",
       "               learning_rate=0.13520045129619862, max_depth=18, n_estimators=150,\n",
       "               random_state=0),\n",
       " {'boosting_type': 'gbdt',\n",
       "  'colsample_bytree': 0.8515260655364685,\n",
       "  'learning_rate': 0.13520045129619862,\n",
       "  'max_depth': 18},\n",
       " 0.04590403848291353,\n",
       " 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8163041169524399, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning + Features Selection with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00063 ### eval_score: 0.23678\n",
      "trial: 0002 ### iterations: 00070 ### eval_score: 0.23779\n",
      "trial: 0003 ### iterations: 00042 ### eval_score: 0.24026\n",
      "trial: 0004 ### iterations: 00052 ### eval_score: 0.23773\n",
      "trial: 0005 ### iterations: 00036 ### eval_score: 0.24991\n",
      "trial: 0006 ### iterations: 00062 ### eval_score: 0.23893\n",
      "trial: 0007 ### iterations: 00133 ### eval_score: 0.23946\n",
      "trial: 0008 ### iterations: 00099 ### eval_score: 0.24318\n",
      "trial: 0009 ### iterations: 00106 ### eval_score: 0.23646\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.24228\n",
      "trial: 0011 ### iterations: 00125 ### eval_score: 0.23753\n",
      "trial: 0012 ### iterations: 00101 ### eval_score: 0.24296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostBoruta(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "            importance_type='shap_importances', max_iter=200,\n",
       "            param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                        'num_leaves': [25, 30, 35]},\n",
       "            train_importance=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH + BORUTA SHAP ###\n",
    "\n",
    "model = BoostBoruta(\n",
    "    clf_lgbm, param_grid=param_grid, max_iter=200, perc=100,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=10, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'learning_rate': 0.1, 'num_leaves': 35, 'max_depth': 10},\n",
       " 0.23645686796387438,\n",
       " 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9083333333333333, (2400,), (2400, 11), (2400, 2))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict_proba(X_clf_valid).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00063 ### eval_score: 0.05079\n",
      "trial: 0002 ### iterations: 00123 ### eval_score: 0.04862\n",
      "trial: 0003 ### iterations: 00150 ### eval_score: 0.04846\n",
      "trial: 0004 ### iterations: 00064 ### eval_score: 0.04951\n",
      "trial: 0005 ### iterations: 00119 ### eval_score: 0.04796\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.04898\n",
      "trial: 0007 ### iterations: 00067 ### eval_score: 0.04754\n",
      "trial: 0008 ### iterations: 00148 ### eval_score: 0.05036\n",
      "trial: 0009 ### iterations: 00080 ### eval_score: 0.04935\n",
      "trial: 0010 ### iterations: 00150 ### eval_score: 0.04769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         importance_type='shap_importances', min_features_to_select=1,\n",
       "         n_iter=10,\n",
       "         param_grid={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018567F78208>,\n",
       "                     'max_depth': [10, 12],\n",
       "                     'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018566F33248>},\n",
       "         sampling_seed=0, train_importance=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH + RECURSIVE FEATURE ELIMINATION (RFE) SHAP ###\n",
    "\n",
    "model = BoostRFE(\n",
    "    regr_lgbm, param_grid=param_dist, min_features_to_select=1, step=1,\n",
    "    n_iter=10, sampling_seed=0,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.2506724789465198, max_depth=12, n_estimators=150,\n",
       "               num_leaves=35, random_state=0),\n",
       " {'learning_rate': 0.2506724789465198, 'num_leaves': 35, 'max_depth': 12},\n",
       " 0.04753836235238756,\n",
       " 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8097639828746837, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('boosting_type', 'max_depth', 'learning_rate', 'colsample_bytree')\n",
      "\n",
      "trial: 0001 ### iterations: 00150 ### eval_score: 0.05458\n",
      "trial: 0002 ### iterations: 00148 ### eval_score: 0.0459\n",
      "trial: 0003 ### iterations: 00111 ### eval_score: 0.04903\n",
      "trial: 0004 ### iterations: 00150 ### eval_score: 0.10224\n",
      "trial: 0005 ### iterations: 00150 ### eval_score: 0.15875\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.04944\n",
      "trial: 0007 ### iterations: 00126 ### eval_score: 0.0471\n",
      "trial: 0008 ### iterations: 00150 ### eval_score: 0.04857\n",
      "trial: 0009 ### iterations: 00150 ### eval_score: 0.05053\n",
      "trial: 0010 ### iterations: 00150 ### eval_score: 0.09805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFA(estimator=LGBMRegressor(n_estimators=150, random_state=0),\n",
       "         importance_type='shap_importances', min_features_to_select=1,\n",
       "         n_iter=10,\n",
       "         param_grid={'boosting_type': <hyperopt.pyll.base.Apply object at 0x000001855ED04288>,\n",
       "                     'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x0000018567F7E3C8>,\n",
       "                     'learning_rate': <hyperopt.pyll.base.Apply object at 0x0000018567F78FC8>,\n",
       "                     'max_depth': <hyperopt.pyll.base.Apply object at 0x0000018567F78B08>},\n",
       "         sampling_seed=0, train_importance=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH HYPEROPT + RECURSIVE FEATURE ADDITION (RFA) SHAP ###\n",
    "\n",
    "model = BoostRFA(\n",
    "    regr_lgbm, param_grid=param_dist_hyperopt, min_features_to_select=1, step=1,\n",
    "    n_iter=10, sampling_seed=0,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "model.fit(\n",
    "    X_regr_train, y_regr_train, trials=Trials(), \n",
    "    eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(colsample_bytree=0.8515260655364685,\n",
       "               learning_rate=0.13520045129619862, max_depth=18, n_estimators=150,\n",
       "               random_state=0),\n",
       " {'boosting_type': 'gbdt',\n",
       "  'colsample_bytree': 0.8515260655364685,\n",
       "  'learning_rate': 0.13520045129619862,\n",
       "  'max_depth': 18},\n",
       " 0.04590403848291353,\n",
       " 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8163041169524399, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM EVAL METRIC SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def AUC(y_true, y_hat):\n",
    "    return 'auc', roc_auc_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00006 ### eval_score: 0.53515\n",
      "trial: 0002 ### iterations: 00004 ### eval_score: 0.5908\n",
      "trial: 0003 ### iterations: 00007 ### eval_score: 0.53593\n",
      "trial: 0004 ### iterations: 00007 ### eval_score: 0.52933\n",
      "trial: 0005 ### iterations: 00014 ### eval_score: 0.58782\n",
      "trial: 0006 ### iterations: 00011 ### eval_score: 0.53378\n",
      "trial: 0007 ### iterations: 00007 ### eval_score: 0.58935\n",
      "trial: 0008 ### iterations: 00007 ### eval_score: 0.53138\n",
      "trial: 0009 ### iterations: 00003 ### eval_score: 0.53113\n",
      "trial: 0010 ### iterations: 00017 ### eval_score: 0.58623\n",
      "trial: 0011 ### iterations: 00009 ### eval_score: 0.58735\n",
      "trial: 0012 ### iterations: 00007 ### eval_score: 0.58713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMClassifier(metric='custom', random_state=0),\n",
       "         greater_is_better=True, min_features_to_select=1,\n",
       "         param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                     'num_leaves': [25, 30, 35]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BoostRFE(\n",
    "    LGBMClassifier(n_estimators=150, random_state=0, metric=\"custom\"), \n",
    "    param_grid=param_grid, min_features_to_select=1, step=1,\n",
    "    greater_is_better=True\n",
    ")\n",
    "model.fit(\n",
    "    X_clf_train, y_clf_train, \n",
    "    eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0, \n",
    "    eval_metric=AUC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORICAL FEATURE SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = [0,1,2]\n",
    "\n",
    "X_clf_train[:,categorical_feature] = (X_clf_train[:,categorical_feature]+100).clip(0).astype(int)\n",
    "X_clf_valid[:,categorical_feature] = (X_clf_valid[:,categorical_feature]+100).clip(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00074 ### eval_score: 0.23709\n",
      "trial: 0002 ### iterations: 00076 ### eval_score: 0.23733\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.23524\n",
      "trial: 0004 ### iterations: 00042 ### eval_score: 0.24027\n",
      "trial: 0005 ### iterations: 00064 ### eval_score: 0.23977\n",
      "trial: 0006 ### iterations: 00055 ### eval_score: 0.23727\n",
      "trial: 0007 ### iterations: 00128 ### eval_score: 0.23446\n",
      "trial: 0008 ### iterations: 00143 ### eval_score: 0.23278\n",
      "trial: 0009 ### iterations: 00111 ### eval_score: 0.23298\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.23798\n",
      "trial: 0011 ### iterations: 00123 ### eval_score: 0.23489\n",
      "trial: 0012 ### iterations: 00128 ### eval_score: 0.23242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1,\n",
       "         param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                     'num_leaves': [25, 30, 35]})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MANUAL PASS categorical_feature WITH NUMPY ARRAYS ###\n",
    "\n",
    "model = BoostRFE(clf_lgbm, param_grid=param_grid, min_features_to_select=1, step=1)\n",
    "model.fit(\n",
    "    X_clf_train, y_clf_train, \n",
    "    eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0,\n",
    "    categorical_feature=categorical_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_train = pd.DataFrame(X_clf_train)\n",
    "X_clf_train[categorical_feature] = X_clf_train[categorical_feature].astype('category')\n",
    "\n",
    "X_clf_valid = pd.DataFrame(X_clf_valid)\n",
    "X_clf_valid[categorical_feature] = X_clf_valid[categorical_feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00074 ### eval_score: 0.23709\n",
      "trial: 0002 ### iterations: 00076 ### eval_score: 0.23733\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.23524\n",
      "trial: 0004 ### iterations: 00042 ### eval_score: 0.24027\n",
      "trial: 0005 ### iterations: 00064 ### eval_score: 0.23977\n",
      "trial: 0006 ### iterations: 00055 ### eval_score: 0.23727\n",
      "trial: 0007 ### iterations: 00128 ### eval_score: 0.23446\n",
      "trial: 0008 ### iterations: 00143 ### eval_score: 0.23278\n",
      "trial: 0009 ### iterations: 00111 ### eval_score: 0.23298\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.23798\n",
      "trial: 0011 ### iterations: 00123 ### eval_score: 0.23489\n",
      "trial: 0012 ### iterations: 00128 ### eval_score: 0.23242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoostRFE(estimator=LGBMClassifier(n_estimators=150, random_state=0),\n",
       "         min_features_to_select=1,\n",
       "         param_grid={'learning_rate': [0.2, 0.1], 'max_depth': [10, 12],\n",
       "                     'num_leaves': [25, 30, 35]})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PASS category COLUMNS IN PANDAS DF ###\n",
    "\n",
    "model = BoostRFE(clf_lgbm, param_grid=param_grid, min_features_to_select=1, step=1)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prova]",
   "language": "python",
   "name": "conda-env-prova-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
