{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "from lightgbm import *\n",
    "\n",
    "from shaphypetune import BoostSearch, BoostBoruta, BoostRFE\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf, y_clf = make_classification(n_samples=8000, n_features=20, n_classes=2, \n",
    "                                   n_informative=4, n_redundant=6, random_state=0)\n",
    "\n",
    "X_clf_train, X_clf_valid, y_clf_train, y_clf_valid = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.3, shuffle=False)\n",
    "\n",
    "X_regr, y_regr = make_classification(n_samples=8000, n_features=20,\n",
    "                                     n_informative=7, random_state=0)\n",
    "\n",
    "X_regr_train, X_regr_valid, y_regr_train, y_regr_valid = train_test_split(\n",
    "    X_regr, y_regr, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate': [0.2, 0.1],\n",
    "    'num_leaves': [25, 30, 35],\n",
    "    'max_depth': [10, 12]\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate': stats.uniform(0.09, 0.25),\n",
    "    'num_leaves': stats.randint(20,40),\n",
    "    'max_depth': [10, 12]\n",
    "}\n",
    "\n",
    "\n",
    "regr_lgbm = LGBMRegressor(random_state=0, n_jobs=-1)\n",
    "clf_lgbm = LGBMClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00047 ### eval_score: 0.25942\n",
      "trial: 0002 ### iterations: 00029 ### eval_score: 0.26879\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.25027\n",
      "trial: 0004 ### iterations: 00035 ### eval_score: 0.26033\n",
      "trial: 0005 ### iterations: 00069 ### eval_score: 0.2497\n",
      "trial: 0006 ### iterations: 00044 ### eval_score: 0.25268\n",
      "trial: 0007 ### iterations: 00111 ### eval_score: 0.25511\n",
      "trial: 0008 ### iterations: 00107 ### eval_score: 0.25491\n",
      "trial: 0009 ### iterations: 00093 ### eval_score: 0.24845\n",
      "trial: 0010 ### iterations: 00107 ### eval_score: 0.24726\n",
      "trial: 0011 ### iterations: 00093 ### eval_score: 0.25091\n",
      "trial: 0012 ### iterations: 00082 ### eval_score: 0.25287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostSearch>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH ###\n",
    "\n",
    "model = BoostSearch(clf_lgbm, param_grid=param_grid)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=12, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.1,\n",
       "  'num_leaves': 35,\n",
       "  'max_depth': 12},\n",
       " 0.24725564683166487)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.90875, (2400,), (2400, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.predict(X_clf_valid, method='predict_proba').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00056 ### eval_score: 0.0544\n",
      "trial: 0002 ### iterations: 00043 ### eval_score: 0.05828\n",
      "trial: 0003 ### iterations: 00038 ### eval_score: 0.06032\n",
      "trial: 0004 ### iterations: 00025 ### eval_score: 0.0604\n",
      "trial: 0005 ### iterations: 00017 ### eval_score: 0.06193\n",
      "trial: 0006 ### iterations: 00139 ### eval_score: 0.05427\n",
      "trial: 0007 ### iterations: 00040 ### eval_score: 0.06256\n",
      "trial: 0008 ### iterations: 00148 ### eval_score: 0.0553\n",
      "trial: 0009 ### iterations: 00053 ### eval_score: 0.06231\n",
      "trial: 0010 ### iterations: 00042 ### eval_score: 0.05609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostSearch>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH ###\n",
    "\n",
    "model = BoostSearch(regr_lgbm, param_grid=param_dist,\n",
    "                    n_iter=10, sampling_seed=0)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.14065173840722262, max_depth=10, n_estimators=150,\n",
       "               num_leaves=25, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.14065173840722262,\n",
       "  'num_leaves': 25,\n",
       "  'max_depth': 10},\n",
       " 0.05426763799282632)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7828351924698709, (2400,), (2400, 21))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostBoruta>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BORUTA ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, max_iter=200, perc=100)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(random_state=0), 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9108333333333334, (2400,), (2400, 9), (2400, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict(X_clf_valid, method='predict_proba').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ELIMINATION (RFE) ###\n",
    "\n",
    "model = BoostRFE(regr_lgbm, min_features_to_select=1, step=1)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(random_state=0), 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8100440630138467, (2400,), (2400, 8), (2400, 9))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostBoruta>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BORUTA SHAP ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, max_iter=200, perc=100,\n",
    "                    importance_type='shap_importances', train_importance=False)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(random_state=0), 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91125, (2400,), (2400, 11), (2400, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict(X_clf_valid, method='predict_proba').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECURSIVE FEATURE ELIMINATION (RFE) SHAP ###\n",
    "\n",
    "model = BoostRFE(regr_lgbm, min_features_to_select=1, step=1,\n",
    "                 importance_type='shap_importances', train_importance=False)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(random_state=0), 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8089993072642051, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning + Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00066 ### eval_score: 0.23684\n",
      "trial: 0002 ### iterations: 00052 ### eval_score: 0.23871\n",
      "trial: 0003 ### iterations: 00049 ### eval_score: 0.24086\n",
      "trial: 0004 ### iterations: 00048 ### eval_score: 0.2382\n",
      "trial: 0005 ### iterations: 00049 ### eval_score: 0.23586\n",
      "trial: 0006 ### iterations: 00053 ### eval_score: 0.23598\n",
      "trial: 0007 ### iterations: 00126 ### eval_score: 0.23237\n",
      "trial: 0008 ### iterations: 00126 ### eval_score: 0.23805\n",
      "trial: 0009 ### iterations: 00101 ### eval_score: 0.23554\n",
      "trial: 0010 ### iterations: 00100 ### eval_score: 0.23165\n",
      "trial: 0011 ### iterations: 00084 ### eval_score: 0.23291\n",
      "trial: 0012 ### iterations: 00087 ### eval_score: 0.23614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostBoruta>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH + BORUTA ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, param_grid=param_grid, max_iter=200, perc=100)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=12, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.1,\n",
       "  'num_leaves': 35,\n",
       "  'max_depth': 12},\n",
       " 0.23165415918498178,\n",
       " 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91375, (2400,), (2400, 9), (2400, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict(X_clf_valid, method='predict_proba').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00150 ### eval_score: 0.04544\n",
      "trial: 0002 ### iterations: 00081 ### eval_score: 0.04838\n",
      "trial: 0003 ### iterations: 00080 ### eval_score: 0.04734\n",
      "trial: 0004 ### iterations: 00107 ### eval_score: 0.0511\n",
      "trial: 0005 ### iterations: 00088 ### eval_score: 0.04701\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.04602\n",
      "trial: 0007 ### iterations: 00086 ### eval_score: 0.0488\n",
      "trial: 0008 ### iterations: 00149 ### eval_score: 0.05066\n",
      "trial: 0009 ### iterations: 00150 ### eval_score: 0.0516\n",
      "trial: 0010 ### iterations: 00115 ### eval_score: 0.04599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH + RECURSIVE FEATURE ELIMINATION (RFE) ###\n",
    "\n",
    "model = BoostRFE(regr_lgbm, param_grid=param_dist, min_features_to_select=1, step=1,\n",
    "                 n_iter=10, sampling_seed=0)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.1350674222191923, max_depth=10, n_estimators=150,\n",
       "               num_leaves=38, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.1350674222191923,\n",
       "  'num_leaves': 38,\n",
       "  'max_depth': 10},\n",
       " 0.04544344630965471,\n",
       " 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8181472856318811, (2400,), (2400, 8), (2400, 9))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning + Features Selection with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00063 ### eval_score: 0.23678\n",
      "trial: 0002 ### iterations: 00070 ### eval_score: 0.23779\n",
      "trial: 0003 ### iterations: 00042 ### eval_score: 0.24026\n",
      "trial: 0004 ### iterations: 00052 ### eval_score: 0.23773\n",
      "trial: 0005 ### iterations: 00036 ### eval_score: 0.24991\n",
      "trial: 0006 ### iterations: 00062 ### eval_score: 0.23893\n",
      "trial: 0007 ### iterations: 00133 ### eval_score: 0.23946\n",
      "trial: 0008 ### iterations: 00099 ### eval_score: 0.24318\n",
      "trial: 0009 ### iterations: 00106 ### eval_score: 0.23646\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.24228\n",
      "trial: 0011 ### iterations: 00125 ### eval_score: 0.23753\n",
      "trial: 0012 ### iterations: 00101 ### eval_score: 0.24296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostBoruta>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH GRID-SEARCH + BORUTA SHAP ###\n",
    "\n",
    "model = BoostBoruta(clf_lgbm, param_grid=param_grid, max_iter=200, perc=100,\n",
    "                    importance_type='shap_importances', train_importance=False)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=10, n_estimators=150, num_leaves=35, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.1,\n",
       "  'num_leaves': 35,\n",
       "  'max_depth': 10},\n",
       " 0.23645686796387438,\n",
       " 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9083333333333333, (2400,), (2400, 11), (2400, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_clf_valid, y_clf_valid), \n",
    " model.predict(X_clf_valid).shape, \n",
    " model.transform(X_clf_valid).shape,\n",
    " model.predict(X_clf_valid, method='predict_proba').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00150 ### eval_score: 0.04646\n",
      "trial: 0002 ### iterations: 00094 ### eval_score: 0.04905\n",
      "trial: 0003 ### iterations: 00094 ### eval_score: 0.04925\n",
      "trial: 0004 ### iterations: 00059 ### eval_score: 0.0514\n",
      "trial: 0005 ### iterations: 00111 ### eval_score: 0.04846\n",
      "trial: 0006 ### iterations: 00150 ### eval_score: 0.04602\n",
      "trial: 0007 ### iterations: 00105 ### eval_score: 0.04966\n",
      "trial: 0008 ### iterations: 00149 ### eval_score: 0.05066\n",
      "trial: 0009 ### iterations: 00150 ### eval_score: 0.0516\n",
      "trial: 0010 ### iterations: 00115 ### eval_score: 0.04599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### HYPERPARAM TUNING WITH RANDOM-SEARCH + RECURSIVE FEATURE ELIMINATION (RFE) SHAP ###\n",
    "\n",
    "model = BoostRFE(regr_lgbm, param_grid=param_dist, min_features_to_select=1, step=1,\n",
    "                 n_iter=10, sampling_seed=0,\n",
    "                 importance_type='shap_importances', train_importance=False)\n",
    "model.fit(X_regr_train, y_regr_train, eval_set=[(X_regr_valid, y_regr_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.17356342265816355, max_depth=12, n_estimators=150,\n",
       "               num_leaves=33, random_state=0),\n",
       " {'n_estimators': 150,\n",
       "  'learning_rate': 0.17356342265816355,\n",
       "  'num_leaves': 33,\n",
       "  'max_depth': 12},\n",
       " 0.04598749053286013,\n",
       " 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_, model.best_params_, model.best_score_, model.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8159701638077123, (2400,), (2400, 9), (2400, 10))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.score(X_regr_valid, y_regr_valid), \n",
    " model.predict(X_regr_valid).shape, \n",
    " model.transform(X_regr_valid).shape,\n",
    " model.predict(X_regr_valid, pred_contrib=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM EVAL METRIC SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def AUC(y_true, y_hat):\n",
    "    return 'auc', roc_auc_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00068 ### eval_score: 0.96755\n",
      "trial: 0002 ### iterations: 00072 ### eval_score: 0.96577\n",
      "trial: 0003 ### iterations: 00067 ### eval_score: 0.96698\n",
      "trial: 0004 ### iterations: 00041 ### eval_score: 0.96632\n",
      "trial: 0005 ### iterations: 00078 ### eval_score: 0.96679\n",
      "trial: 0006 ### iterations: 00068 ### eval_score: 0.96626\n",
      "trial: 0007 ### iterations: 00126 ### eval_score: 0.9669\n",
      "trial: 0008 ### iterations: 00133 ### eval_score: 0.96591\n",
      "trial: 0009 ### iterations: 00115 ### eval_score: 0.96816\n",
      "trial: 0010 ### iterations: 00106 ### eval_score: 0.96789\n",
      "trial: 0011 ### iterations: 00101 ### eval_score: 0.96727\n",
      "trial: 0012 ### iterations: 00108 ### eval_score: 0.96755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BoostRFE(LGBMClassifier(random_state=0, metric=\"custom\"), \n",
    "                 param_grid=param_grid, min_features_to_select=1, step=1,\n",
    "                 greater_is_better=True)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0,\n",
    "          eval_metric=AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORICAL FEATURE SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = [0,1,2]\n",
    "\n",
    "X_clf_train[:,categorical_feature] = (X_clf_train[:,categorical_feature]+100).clip(0).astype(int)\n",
    "X_clf_valid[:,categorical_feature] = (X_clf_valid[:,categorical_feature]+100).clip(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00074 ### eval_score: 0.23709\n",
      "trial: 0002 ### iterations: 00076 ### eval_score: 0.23733\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.23524\n",
      "trial: 0004 ### iterations: 00042 ### eval_score: 0.24027\n",
      "trial: 0005 ### iterations: 00064 ### eval_score: 0.23977\n",
      "trial: 0006 ### iterations: 00055 ### eval_score: 0.23727\n",
      "trial: 0007 ### iterations: 00128 ### eval_score: 0.23446\n",
      "trial: 0008 ### iterations: 00143 ### eval_score: 0.23278\n",
      "trial: 0009 ### iterations: 00111 ### eval_score: 0.23298\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.23798\n",
      "trial: 0011 ### iterations: 00123 ### eval_score: 0.23489\n",
      "trial: 0012 ### iterations: 00128 ### eval_score: 0.23242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MANUAL PASS categorical_feature WITH NUMPY ARRAYS ###\n",
    "\n",
    "model = BoostRFE(clf_lgbm, param_grid=param_grid, min_features_to_select=1, step=1)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0,\n",
    "          categorical_feature=categorical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf_train = pd.DataFrame(X_clf_train)\n",
    "X_clf_train[categorical_feature] = X_clf_train[categorical_feature].astype('category')\n",
    "\n",
    "X_clf_valid = pd.DataFrame(X_clf_valid)\n",
    "X_clf_valid[categorical_feature] = X_clf_valid[categorical_feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 trials detected for ('n_estimators', 'learning_rate', 'num_leaves', 'max_depth')\n",
      "\n",
      "trial: 0001 ### iterations: 00074 ### eval_score: 0.23709\n",
      "trial: 0002 ### iterations: 00076 ### eval_score: 0.23733\n",
      "trial: 0003 ### iterations: 00048 ### eval_score: 0.23524\n",
      "trial: 0004 ### iterations: 00042 ### eval_score: 0.24027\n",
      "trial: 0005 ### iterations: 00064 ### eval_score: 0.23977\n",
      "trial: 0006 ### iterations: 00055 ### eval_score: 0.23727\n",
      "trial: 0007 ### iterations: 00128 ### eval_score: 0.23446\n",
      "trial: 0008 ### iterations: 00143 ### eval_score: 0.23278\n",
      "trial: 0009 ### iterations: 00111 ### eval_score: 0.23298\n",
      "trial: 0010 ### iterations: 00090 ### eval_score: 0.23798\n",
      "trial: 0011 ### iterations: 00123 ### eval_score: 0.23489\n",
      "trial: 0012 ### iterations: 00128 ### eval_score: 0.23242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PASS category COLUMNS IN PANDAS DF ###\n",
    "\n",
    "model = BoostRFE(clf_lgbm, param_grid=param_grid, min_features_to_select=1, step=1)\n",
    "model.fit(X_clf_train, y_clf_train, eval_set=[(X_clf_valid, y_clf_valid)], early_stopping_rounds=6, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
